{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-18T15:51:59.712463Z",
     "start_time": "2020-09-18T15:51:59.552430Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# 0 Housekeeping. Clear variable space\n",
    "########################################################################################################################\n",
    "from IPython import get_ipython  # run magic commands\n",
    "\n",
    "ipython = get_ipython()\n",
    "ipython.magic(\"reset -f\")\n",
    "ipython = get_ipython()\n",
    "ipython.magic(\"load_ext autoreload\")\n",
    "ipython.magic(\"autoreload 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-18T15:51:59.822467Z",
     "start_time": "2020-09-18T15:51:59.738441Z"
    }
   },
   "outputs": [],
   "source": [
    "# 1 Import Libraries and Set Global Parameters\n",
    "####################################################################################################\n",
    "# 1.1 Import Python Libraries\n",
    "############################################\n",
    "from datetime import datetime\n",
    "import os, sys, shutil\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-18T15:51:59.983549Z",
     "start_time": "2020-09-18T15:51:59.896842Z"
    }
   },
   "outputs": [],
   "source": [
    "# 1.2 Set Global Parameters\n",
    "############################################\n",
    "if os.getlogin() == \"WylieTimmerman\":\n",
    "    path_working = r\"C:\\OD\\OneDrive - Foursquare ITP\\Projects\\WMATA_AVL\"\n",
    "    os.chdir(os.path.join(path_working))\n",
    "    sys.path.append(r\"C:\\OD\\OneDrive - Foursquare ITP\\Projects\\WMATA_AVL\")\n",
    "    path_sp = r\"C:\\Users\\WylieTimmerman\\Documents\\projects_local\\wmata_avl_local\"\n",
    "    path_source_data = os.path.join(path_sp,\"data\",\"00-raw\")\n",
    "    path_processed_data = os.path.join(path_sp, \"data\",\"02-processed\")\n",
    "    path_segments = os.path.join(path_working,\"data\",\"02-processed\")\n",
    "elif os.getlogin() == \"abibeka\":\n",
    "    path_working = r\"C:\\Users\\abibeka\\OneDrive - Kittelson & Associates, Inc\\Documents\\Github\\WMATA_AVL\"\n",
    "    os.chdir(os.path.join(path_working))\n",
    "    sys.path.append(path_working)\n",
    "    path_source_data = r\"C:\\Users\\abibeka\\OneDrive - Kittelson & Associates, Inc\\Documents\\WMATA-AVL\\Data\"\n",
    "    path_processed_data = os.path.join(path_source_data, \"ProcessedData\")\n",
    "    path_segments = path_processed_data\n",
    "elif os.getlogin() == \"E048374\":\n",
    "    # Working Paths\n",
    "    path_working = r\"C:\\Users\\E048374\\OneDrive - WMATA\\rawnav_rachel_fork\\WMATA_AVL\"\n",
    "    os.chdir(os.path.join(path_working))\n",
    "    sys.path.append(r\"C:\\Users\\E048374\\OneDrive - WMATA\\rawnav_rachel_fork\\WMATA_AVL\")\n",
    "    path_source_data = r\"\\\\l-600730\\RawNavArchive\"\n",
    "    path_sp = r\"C:\\Users\\E048374\\Documents\\RawNav\"\n",
    "    path_processed_data = os.path.join(path_sp, \"data\", \"02-processed\")\n",
    "    path_segments = os.path.join(path_working, \"data\", \"02-processed\")\n",
    "    \n",
    "else:\n",
    "    raise FileNotFoundError(\"Define the path_working, path_source_data, gtfs_dir, \\\n",
    "                            ZippedFilesloc, and path_processed_data in a new elif block\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-18T15:52:00.142073Z",
     "start_time": "2020-09-18T15:52:00.056841Z"
    }
   },
   "outputs": [],
   "source": [
    "# Globals\n",
    "q_jump_route_list = ['52']\n",
    "analysis_routes = q_jump_route_list\n",
    "# analysis_routes = ['S1']\n",
    "# analysis_routes = ['S1', 'S9', 'H4', 'G8', '64']\n",
    "# analysis_routes = ['S2','S4','H1','H2','H3','79','W47']\n",
    "# took out Sunday bc doesn't exist in my test data (BAM)\n",
    "analysis_days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday']\n",
    "# analysis_days = ['Wednesday','Thursday','Friday']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-18T15:52:00.301253Z",
     "start_time": "2020-09-18T15:52:00.217624Z"
    }
   },
   "outputs": [],
   "source": [
    "# EPSG code for WMATA-area work\n",
    "wmata_crs = 2248\n",
    "# 1.3 Import User-Defined Package\n",
    "############################################\n",
    "import wmatarawnav as wr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-18T17:11:38.628237Z",
     "start_time": "2020-09-18T17:11:38.385222Z"
    }
   },
   "outputs": [],
   "source": [
    "segments = (\n",
    "    gpd.read_file(os.path.join(path_segments,\"seg_5201_by_stop.geojson\"), dtype={'pattern':'int32'})\n",
    "    .to_crs(wmata_crs)\n",
    ")[['seg_name_id', 'name_str', 'geoid', 'stop_id',\n",
    "       'length', 'geometry']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-18T17:11:38.808229Z",
     "start_time": "2020-09-18T17:11:38.713231Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seg_name_id</th>\n",
       "      <th>geoid</th>\n",
       "      <th>stop_id</th>\n",
       "      <th>route</th>\n",
       "      <th>pattern</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14th_25</td>\n",
       "      <td>7243</td>\n",
       "      <td>19143</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  seg_name_id  geoid  stop_id route  pattern\n",
       "0     14th_25   7243    19143    52        1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seg_pattern = pd.read_csv(os.path.join(path_segments,\"stop_seq_pattern_5201_by_stop.csv\"),\n",
    "                         dtype={'route':str, 'PATTERN_ID':str, 'pattern':'int32'})\n",
    "seg_pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-18T17:11:39.174760Z",
     "start_time": "2020-09-18T17:11:39.082568Z"
    }
   },
   "outputs": [],
   "source": [
    "wmata_schedule_dat = (\n",
    "    pd.read_csv(\n",
    "        os.path.join(path_sp, \"wmata_schedule_data_q_jump_routes.csv\"),\n",
    "        index_col = 0\n",
    "    )\n",
    "    .reset_index(drop=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-18T17:19:10.480895Z",
     "start_time": "2020-09-18T17:19:10.395895Z"
    }
   },
   "outputs": [],
   "source": [
    "# 3 Merge Additional Geometry\n",
    "####################################################################################################\n",
    "\n",
    "# 3.1 Rawnav-Segment ########################\n",
    "\n",
    "# Make Output Directory\n",
    "path_seg_summary = os.path.join(path_processed_data,\"by_stop\", \"segment_summary.parquet\")\n",
    "shutil.rmtree(path_seg_summary, ignore_errors=True) \n",
    "os.mkdir(path_seg_summary)\n",
    "\n",
    "path_seg_index = os.path.join(path_processed_data,\"by_stop\", \"segment_index.parquet\")\n",
    "shutil.rmtree(path_seg_index, ignore_errors=True) \n",
    "os.mkdir(path_seg_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-18T17:19:20.057322Z",
     "start_time": "2020-09-18T17:19:11.581223Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "Processing analysis route 52\n",
      "Processing analysis route 52 for Monday...\n",
      "Processing segment 14th_25 ...\n",
      "Processing analysis route 52 for Tuesday...\n",
      "Processing segment 14th_25 ...\n",
      "Processing analysis route 52 for Wednesday...\n",
      "Processing segment 14th_25 ...\n",
      "Processing analysis route 52 for Thursday...\n",
      "Processing segment 14th_25 ...\n",
      "Processing analysis route 52 for Friday...\n",
      "Processing segment 14th_25 ...\n",
      "Processing analysis route 52 for Saturday...\n",
      "Processing segment 14th_25 ...\n"
     ]
    }
   ],
   "source": [
    "# Iterate\n",
    "for analysis_route in analysis_routes:\n",
    "    print(\"*\" * 100)\n",
    "    print(f'Processing analysis route {analysis_route}')\n",
    "    for analysis_day in analysis_days:\n",
    "        print(f'Processing analysis route {analysis_route} for {analysis_day}...')\n",
    "        \n",
    "        # Reload data\n",
    "        try:\n",
    "            rawnav_dat = (\n",
    "                wr.read_cleaned_rawnav(\n",
    "                   analysis_routes_ = analysis_route,\n",
    "                   analysis_days_ = analysis_day,\n",
    "                   path = os.path.join(path_processed_data, \"rawnav_data.parquet\"))\n",
    "                .drop(columns=['blank', 'lat_raw', 'long_raw', 'sat_cnt'])\n",
    "                )\n",
    "        except:\n",
    "            print(f'No data on analysis route {analysis_route} for {analysis_day}')\n",
    "            continue\n",
    "        else:\n",
    "   \n",
    "            # Reload Data\n",
    "            rawnav_summary_dat = (\n",
    "                wr.read_cleaned_rawnav(\n",
    "                    analysis_routes_ = analysis_route,\n",
    "                    analysis_days_ = analysis_day,\n",
    "                    path = os.path.join(path_processed_data, \"rawnav_summary.parquet\")\n",
    "                )\n",
    "            )\n",
    "\n",
    "            # Subset Rawnav Data to Records Desired\n",
    "            rawnav_summary_dat = rawnav_summary_dat.query('not (run_duration_from_sec < 600 | dist_odom_mi < 2)')\n",
    "            \n",
    "            rawnav_qjump_dat = rawnav_dat.merge(rawnav_summary_dat[['filename', 'index_run_start']], \n",
    "                                                on=['filename', 'index_run_start'],\n",
    "                                                how='right')\n",
    "            \n",
    "            # Address Remaining Col Format issues\n",
    "            rawnav_qjump_gdf = (\n",
    "                gpd.GeoDataFrame(\n",
    "                    rawnav_qjump_dat, \n",
    "                    geometry = gpd.points_from_xy(\n",
    "                        rawnav_qjump_dat.long,\n",
    "                        rawnav_qjump_dat.lat\n",
    "                    ),\n",
    "                    crs='EPSG:4326')\n",
    "                .to_crs(epsg=wmata_crs)\n",
    "            )\n",
    "    \n",
    "            # Iterate on over Pattern-Segments Combinations Applicable to Route\n",
    "            xwalk_seg_pattern_subset = seg_pattern[['route','pattern','seg_name_id']].copy()\n",
    "                        \n",
    "            for seg in xwalk_seg_pattern_subset.seg_name_id.unique():\n",
    "                print('Processing segment {} ...'.format(seg))\n",
    "\n",
    "                # We pass the rawnav data and summary tables, check against a segment,\n",
    "                # and use the patterns_by_seg to indicate which patterns should be examined\n",
    "                index_run_segment_start_end, summary_run_segment = (\n",
    "                    wr.merge_rawnav_segment(\n",
    "                        rawnav_gdf_=rawnav_qjump_gdf,\n",
    "                        rawnav_sum_dat_=rawnav_summary_dat,\n",
    "                        target_=segments.loc[segments.seg_name_id == seg],\n",
    "                        patterns_by_seg_=xwalk_seg_pattern_subset.loc[xwalk_seg_pattern_subset.seg_name_id == seg]\n",
    "                    )\n",
    "                )\n",
    "                # Note that because seg_pattern_first_last is defined for route and pattern,\n",
    "                # our summary will implicitly drop any runs that are on 'wrong' pattern(s) for \n",
    "                # a route. \n",
    "                \n",
    "                index_run_segment_start_end['wday'] = analysis_day\n",
    "                summary_run_segment['wday'] = analysis_day\n",
    "                \n",
    "                # The additional partitioning here is excessive, but if fits better in the \n",
    "                # iterative/chunking process above\n",
    "                pq.write_to_dataset(\n",
    "                    table = pa.Table.from_pandas(summary_run_segment),\n",
    "                    root_path = path_seg_summary,\n",
    "                    partition_cols = ['route','wday','seg_name_id']\n",
    "                )\n",
    "                \n",
    "                pq.write_to_dataset(\n",
    "                    table = pa.Table.from_pandas(index_run_segment_start_end),\n",
    "                    root_path = path_seg_index,\n",
    "                    partition_cols = ['route','wday','seg_name_id']\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (rawnav)",
   "language": "python",
   "name": "rawnav"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
