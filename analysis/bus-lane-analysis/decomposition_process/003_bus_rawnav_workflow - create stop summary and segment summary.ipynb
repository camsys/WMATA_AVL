{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# find nearest stops and segment ends "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T18:31:15.550969Z",
     "start_time": "2020-10-06T18:31:14.098014Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run Section 1 Import Libraries and Set Global Parameters...\n"
     ]
    }
   ],
   "source": [
    "# 0 Housekeeping. Clear variable space\n",
    "########################################################################################################################\n",
    "from IPython import get_ipython  # run magic commands\n",
    "ipython = get_ipython()\n",
    "ipython.magic(\"reset -f\")\n",
    "ipython = get_ipython()\n",
    "#https://stackoverflow.com/questions/36572282/ipython-autoreload-magic-function-not-found\n",
    "ipython.magic(\"load_ext autoreload\")\n",
    "ipython.magic(\"autoreload 2\")\n",
    "# 1 Import Libraries and Set Global Parameters\n",
    "########################################################################################################################\n",
    "# 1.1 Import Python Libraries\n",
    "############################################\n",
    "from datetime import datetime\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import shutil\n",
    "print(\"Run Section 1 Import Libraries and Set Global Parameters...\")\n",
    "begin_time = datetime.now()\n",
    "import os, sys, pandas as pd, geopandas as gpd\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "    warnings.simplefilter(\"ignore\")  # Stop Pandas warnings\n",
    "    \n",
    "path_working = r\"C:\\Users\\E048374\\OneDrive - WMATA\\rawnav_rachel_fork\\WMATA_AVL\"\n",
    "os.chdir(os.path.join(path_working))\n",
    "sys.path.append(r\"C:\\Users\\E048374\\OneDrive - WMATA\\rawnav_rachel_fork\\WMATA_AVL\")\n",
    "path_source_data = r\"\\\\l-600730\\RawNavArchive\"\n",
    "path_sp = r\"C:\\Users\\E048374\\Documents\\RawNav\"\n",
    "path_processed_data = os.path.join(path_working, \"data\", \"02-processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T18:31:17.845256Z",
     "start_time": "2020-10-06T18:31:17.761224Z"
    }
   },
   "outputs": [],
   "source": [
    "# Globals\n",
    "\n",
    "q_jump_route_list = ['52']\n",
    "pattern_id = '5201' # see schedule filename below -- probably could just have full schedule..\n",
    "analysis_routes = q_jump_route_list\n",
    "analysis_days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "wmata_crs = 2248"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T22:20:51.724313Z",
     "start_time": "2020-09-30T22:20:49.863017Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run Time Section 1 Import Libraries and Set Global Parameters : 0:00:06\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "# 1.3 Import User-Defined Package\n",
    "############################################\n",
    "import wmatarawnav as wr\n",
    "\n",
    "executionTime = str(datetime.now() - begin_time).split('.')[0]\n",
    "print(\"Run Time Section 1 Import Libraries and Set Global Parameters : {}\".format(executionTime))\n",
    "print(\"*\" * 100)\n",
    "\n",
    "wmata_schedule_dat = (\n",
    "    pd.read_csv(\n",
    "        os.path.join(path_processed_data, f\"bus_sched_{pattern_id}.csv\")\n",
    "        ,dtype={'pattern':'int32','route':'str'}\n",
    "    )\n",
    ")\n",
    "\n",
    "wmata_schedule_gdf = (\n",
    "    gpd.GeoDataFrame(\n",
    "        wmata_schedule_dat, \n",
    "        geometry = gpd.points_from_xy(wmata_schedule_dat.stop_lon,wmata_schedule_dat.stop_lat),\n",
    "        crs='EPSG:4326'\n",
    "    )\n",
    "    .to_crs(epsg=wmata_crs)\n",
    ")\n",
    "\n",
    "# Make Output Directory\n",
    "path_stop_summary = os.path.join(path_processed_data, \"stop_summary.parquet\")\n",
    "if not os.path.isdir(path_stop_summary):\n",
    "    os.mkdir(path_stop_summary)\n",
    "\n",
    "path_stop_index = os.path.join(path_processed_data, \"stop_index.parquet\")\n",
    "if not os.path.isdir(path_stop_index):\n",
    "    os.mkdir(path_stop_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T22:23:50.705305Z",
     "start_time": "2020-09-30T22:21:47.050579Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "Processing analysis route 52\n",
      "Processing analysis route 52 for Monday...\n",
      "deleted 77 rows of 2240 rows with distance to the nearest stop > 100 ft. from index table\n",
      "deleted 5 of 2163 stops with incorrect order from index table\n",
      "Processing analysis route 52 for Tuesday...\n",
      "deleted 60 rows of 3400 rows with distance to the nearest stop > 100 ft. from index table\n",
      "deleted 0 of 3340 stops with incorrect order from index table\n",
      "Processing analysis route 52 for Wednesday...\n",
      "deleted 26 rows of 2840 rows with distance to the nearest stop > 100 ft. from index table\n",
      "deleted 0 of 2814 stops with incorrect order from index table\n",
      "Processing analysis route 52 for Thursday...\n",
      "deleted 298 rows of 2800 rows with distance to the nearest stop > 100 ft. from index table\n",
      "deleted 0 of 2502 stops with incorrect order from index table\n",
      "Processing analysis route 52 for Friday...\n",
      "deleted 242 rows of 4560 rows with distance to the nearest stop > 100 ft. from index table\n",
      "deleted 0 of 4318 stops with incorrect order from index table\n",
      "Processing analysis route 52 for Saturday...\n",
      "deleted 27 rows of 1840 rows with distance to the nearest stop > 100 ft. from index table\n",
      "deleted 0 of 1813 stops with incorrect order from index table\n",
      "Processing analysis route 52 for Sunday...\n",
      "deleted 32 rows of 1160 rows with distance to the nearest stop > 100 ft. from index table\n",
      "deleted 0 of 1128 stops with incorrect order from index table\n",
      "Run Time Section Section 2: Read, analyze and summarize rawnav, WMATA schedule data : 0:03:06\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "for analysis_route in analysis_routes:\n",
    "    print(\"*\" * 100)\n",
    "    print('Processing analysis route {}'.format(analysis_route))\n",
    "    for analysis_day in analysis_days:\n",
    "        print('Processing analysis route {} for {}...'.format(analysis_route,analysis_day))\n",
    "                \n",
    "        # Reload data\n",
    "        try:\n",
    "            rawnav_dat = (\n",
    "                wr.read_cleaned_rawnav(\n",
    "                   analysis_routes_ = analysis_route,\n",
    "                   analysis_days_ = analysis_day,\n",
    "                   path = os.path.join(path_processed_data, \"rawnav_data.parquet\")\n",
    "                )\n",
    "                .drop(columns=['blank', 'lat_raw', 'long_raw', 'sat_cnt'])\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(e)  # usually no data found or something similar\n",
    "            continue\n",
    "        else:\n",
    "\n",
    "            rawnav_summary_dat = (\n",
    "                wr.read_cleaned_rawnav(\n",
    "                    analysis_routes_ = analysis_route,\n",
    "                    analysis_days_ = analysis_day,\n",
    "                    path = os.path.join(path_processed_data, \"rawnav_summary.parquet\")\n",
    "                )\n",
    "            )\n",
    "\n",
    "            # Subset Rawnav Data to Records Desired\n",
    "            rawnav_summary_dat = rawnav_summary_dat.query('not (run_duration_from_sec < 600 | dist_odom_mi < 2)')\n",
    "            \n",
    "            rawnav_summary_keys_col = rawnav_summary_dat[['filename', 'index_run_start']]\n",
    "            \n",
    "            rawnav_qjump_dat = rawnav_dat.merge(rawnav_summary_keys_col,\n",
    "                                                on=['filename', 'index_run_start'],\n",
    "                                                how='right')\n",
    "\n",
    "            rawnav_qjump_gdf = (\n",
    "                gpd.GeoDataFrame(\n",
    "                    rawnav_qjump_dat,\n",
    "                    geometry=gpd.points_from_xy(rawnav_qjump_dat.long, rawnav_qjump_dat.lat),\n",
    "                    crs='EPSG:4326'\n",
    "                )\n",
    "                .to_crs(epsg=wmata_crs)\n",
    "            )\n",
    "\n",
    "        stop_summary, stop_index = (\n",
    "            wr.merge_rawnav_wmata_schedule(\n",
    "                analysis_route_=analysis_route,\n",
    "                analysis_day_=analysis_day,\n",
    "                rawnav_dat_=rawnav_qjump_gdf,\n",
    "                rawnav_sum_dat_=rawnav_summary_dat,\n",
    "                wmata_schedule_dat_=wmata_schedule_gdf\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        if type(stop_summary) == type(None):\n",
    "            print('No data on analysis route {} for {}'.format(analysis_route,analysis_day))\n",
    "            continue\n",
    "        \n",
    "        # Write Summary Table \n",
    "        shutil.rmtree(\n",
    "            os.path.join(\n",
    "                path_stop_summary,\n",
    "                \"route={}\".format(analysis_route),\n",
    "                \"wday={}\".format(analysis_day)\n",
    "            ),\n",
    "            ignore_errors=True\n",
    "        ) \n",
    "        \n",
    "        pq.write_to_dataset(\n",
    "            table=pa.Table.from_pandas(stop_summary),\n",
    "            root_path=path_stop_summary,\n",
    "            partition_cols=['route', 'wday']\n",
    "        )\n",
    "        \n",
    "        # Write Index Table\n",
    "        shutil.rmtree(\n",
    "            os.path.join(\n",
    "                path_stop_index,\n",
    "                \"route={}\".format(analysis_route),\n",
    "                \"wday={}\".format(analysis_day)\n",
    "            ),\n",
    "            ignore_errors=True\n",
    "        ) \n",
    "        \n",
    "        stop_index = wr.drop_geometry(stop_index)\n",
    "        \n",
    "        stop_index = stop_index.assign(wday=analysis_day)\n",
    "                \n",
    "        pq.write_to_dataset(\n",
    "            table=pa.Table.from_pandas(stop_index),\n",
    "            root_path=path_stop_index,\n",
    "            partition_cols=['route', 'wday']\n",
    "        )\n",
    "\n",
    "executionTime = str(datetime.now() - begin_time).split('.')[0]\n",
    "print(\n",
    "      \"Run Time Section Section 2: Read, analyze and summarize rawnav, WMATA schedule data : {}\"\n",
    "      .format(executionTime)\n",
    ")\n",
    "print(\"*\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# find nearest rawnav to segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T18:31:33.639549Z",
     "start_time": "2020-10-06T18:31:33.033334Z"
    }
   },
   "outputs": [],
   "source": [
    "segments = (\n",
    "    gpd.read_file(os.path.join(path_processed_data,\"seg_5201_by_intersection.geojson\"), dtype={'pattern':'int32'})\n",
    "    .to_crs(wmata_crs)\n",
    ")[['seg_name_id', 'name_str', 'geoid', 'stop_id',\n",
    "       'length', 'geometry']]\n",
    "\n",
    "seg_pattern = pd.read_csv(os.path.join(path_processed_data,\"stop_seq_pattern_5201_by_intersection.csv\"),\n",
    "                         dtype={'route':str, 'PATTERN_ID':str, 'pattern':'int32'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T18:32:03.956884Z",
     "start_time": "2020-10-06T18:32:03.881537Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seg_name_id</th>\n",
       "      <th>name_str</th>\n",
       "      <th>geoid</th>\n",
       "      <th>stop_id</th>\n",
       "      <th>length</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14th_12</td>\n",
       "      <td>14th Street Northwest</td>\n",
       "      <td>16203</td>\n",
       "      <td>21627</td>\n",
       "      <td>467.329723</td>\n",
       "      <td>LINESTRING (1303075.006 459187.470, 1303073.08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14th_14</td>\n",
       "      <td>14th Street Northwest</td>\n",
       "      <td>16662</td>\n",
       "      <td>19066</td>\n",
       "      <td>346.561992</td>\n",
       "      <td>LINESTRING (1303075.006 459187.470, 1303077.50...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14th_17</td>\n",
       "      <td>14th Street Northwest</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>303.211388</td>\n",
       "      <td>LINESTRING (1303132.383 458540.266, 1303130.54...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14th_21</td>\n",
       "      <td>14th Street Northwest</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>87.652569</td>\n",
       "      <td>LINESTRING (1303132.383 458540.266, 1303138.89...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14th_22</td>\n",
       "      <td>14th Street Northwest</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>272.507588</td>\n",
       "      <td>LINESTRING (1303138.895 458452.856, 1303140.67...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14th_24</td>\n",
       "      <td>14th Street Northwest</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>78.552727</td>\n",
       "      <td>LINESTRING (1303159.851 458181.155, 1303166.08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14th_25</td>\n",
       "      <td>14th Street Northwest</td>\n",
       "      <td>7243</td>\n",
       "      <td>19143</td>\n",
       "      <td>284.194639</td>\n",
       "      <td>LINESTRING (1303166.082 458102.850, 1303168.09...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  seg_name_id               name_str  geoid  stop_id      length  \\\n",
       "0     14th_12  14th Street Northwest  16203    21627  467.329723   \n",
       "1     14th_14  14th Street Northwest  16662    19066  346.561992   \n",
       "2     14th_17  14th Street Northwest      0        0  303.211388   \n",
       "3     14th_21  14th Street Northwest      0        0   87.652569   \n",
       "4     14th_22  14th Street Northwest      0        0  272.507588   \n",
       "5     14th_24  14th Street Northwest      0        0   78.552727   \n",
       "6     14th_25  14th Street Northwest   7243    19143  284.194639   \n",
       "\n",
       "                                            geometry  \n",
       "0  LINESTRING (1303075.006 459187.470, 1303073.08...  \n",
       "1  LINESTRING (1303075.006 459187.470, 1303077.50...  \n",
       "2  LINESTRING (1303132.383 458540.266, 1303130.54...  \n",
       "3  LINESTRING (1303132.383 458540.266, 1303138.89...  \n",
       "4  LINESTRING (1303138.895 458452.856, 1303140.67...  \n",
       "5  LINESTRING (1303159.851 458181.155, 1303166.08...  \n",
       "6  LINESTRING (1303166.082 458102.850, 1303168.09...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T18:32:07.931133Z",
     "start_time": "2020-10-06T18:32:07.857131Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seg_name_id</th>\n",
       "      <th>geoid</th>\n",
       "      <th>stop_id</th>\n",
       "      <th>route</th>\n",
       "      <th>pattern</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14th_12</td>\n",
       "      <td>16203</td>\n",
       "      <td>21627</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14th_14</td>\n",
       "      <td>16662</td>\n",
       "      <td>19066</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14th_17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14th_21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14th_22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14th_24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14th_25</td>\n",
       "      <td>7243</td>\n",
       "      <td>19143</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  seg_name_id  geoid  stop_id route  pattern\n",
       "0     14th_12  16203    21627    52        1\n",
       "1     14th_14  16662    19066    52        1\n",
       "2     14th_17      0        0    52        1\n",
       "3     14th_21      0        0    52        1\n",
       "4     14th_22      0        0    52        1\n",
       "5     14th_24      0        0    52        1\n",
       "6     14th_25   7243    19143    52        1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seg_pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T22:24:28.969774Z",
     "start_time": "2020-09-30T22:24:28.737799Z"
    }
   },
   "outputs": [],
   "source": [
    "# Make Output Directory\n",
    "path_seg_summary = os.path.join(path_processed_data, \"segment_summary.parquet\")\n",
    "shutil.rmtree(path_seg_summary, ignore_errors=True) \n",
    "os.mkdir(path_seg_summary)\n",
    "\n",
    "path_seg_index = os.path.join(path_processed_data, \"segment_index.parquet\")\n",
    "shutil.rmtree(path_seg_index, ignore_errors=True) \n",
    "os.mkdir(path_seg_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T22:30:00.603287Z",
     "start_time": "2020-09-30T22:24:29.336643Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "Processing analysis route 52\n",
      "Processing analysis route 52 for Monday...\n",
      "Processing segment 14th_12 ...\n",
      "Processing segment 14th_14 ...\n",
      "Processing segment 14th_17 ...\n",
      "Processing segment 14th_21 ...\n",
      "Processing segment 14th_22 ...\n",
      "Processing segment 14th_24 ...\n",
      "Processing segment 14th_25 ...\n",
      "Processing analysis route 52 for Tuesday...\n",
      "Processing segment 14th_12 ...\n",
      "Processing segment 14th_14 ...\n",
      "Processing segment 14th_17 ...\n",
      "Processing segment 14th_21 ...\n",
      "Processing segment 14th_22 ...\n",
      "Processing segment 14th_24 ...\n",
      "Processing segment 14th_25 ...\n",
      "Processing analysis route 52 for Wednesday...\n",
      "Processing segment 14th_12 ...\n",
      "Processing segment 14th_14 ...\n",
      "Processing segment 14th_17 ...\n",
      "Processing segment 14th_21 ...\n",
      "Processing segment 14th_22 ...\n",
      "Processing segment 14th_24 ...\n",
      "Processing segment 14th_25 ...\n",
      "Processing analysis route 52 for Thursday...\n",
      "Processing segment 14th_12 ...\n",
      "Processing segment 14th_14 ...\n",
      "Processing segment 14th_17 ...\n",
      "Processing segment 14th_21 ...\n",
      "Processing segment 14th_22 ...\n",
      "Processing segment 14th_24 ...\n",
      "Processing segment 14th_25 ...\n",
      "Processing analysis route 52 for Friday...\n",
      "Processing segment 14th_12 ...\n",
      "Processing segment 14th_14 ...\n",
      "Processing segment 14th_17 ...\n",
      "Processing segment 14th_21 ...\n",
      "Processing segment 14th_22 ...\n",
      "Processing segment 14th_24 ...\n",
      "Processing segment 14th_25 ...\n",
      "Processing analysis route 52 for Saturday...\n",
      "Processing segment 14th_12 ...\n",
      "Processing segment 14th_14 ...\n",
      "Processing segment 14th_17 ...\n",
      "Processing segment 14th_21 ...\n",
      "Processing segment 14th_22 ...\n",
      "Processing segment 14th_24 ...\n",
      "Processing segment 14th_25 ...\n",
      "Processing analysis route 52 for Sunday...\n",
      "Processing segment 14th_12 ...\n",
      "Processing segment 14th_14 ...\n",
      "Processing segment 14th_17 ...\n",
      "Processing segment 14th_21 ...\n",
      "Processing segment 14th_22 ...\n",
      "Processing segment 14th_24 ...\n",
      "Processing segment 14th_25 ...\n"
     ]
    }
   ],
   "source": [
    "# 3 Merge Additional Geometry\n",
    "####################################################################################################\n",
    "\n",
    "# 3.1 Rawnav-Segment ########################\n",
    "# Iterate\n",
    "for analysis_route in analysis_routes:\n",
    "    print(\"*\" * 100)\n",
    "    print(f'Processing analysis route {analysis_route}')\n",
    "    for analysis_day in analysis_days:\n",
    "        print(f'Processing analysis route {analysis_route} for {analysis_day}...')\n",
    "        \n",
    "        # Reload data\n",
    "        try:\n",
    "            rawnav_dat = (\n",
    "                wr.read_cleaned_rawnav(\n",
    "                   analysis_routes_ = analysis_route,\n",
    "                   analysis_days_ = analysis_day,\n",
    "                   path = os.path.join(path_processed_data, \"rawnav_data.parquet\"))\n",
    "                .drop(columns=['blank', 'lat_raw', 'long_raw', 'sat_cnt'])\n",
    "                )\n",
    "        except:\n",
    "            print(f'No data on analysis route {analysis_route} for {analysis_day}')\n",
    "            continue\n",
    "        else:\n",
    "   \n",
    "            # Reload Data\n",
    "            rawnav_summary_dat = (\n",
    "                wr.read_cleaned_rawnav(\n",
    "                    analysis_routes_ = analysis_route,\n",
    "                    analysis_days_ = analysis_day,\n",
    "                    path = os.path.join(path_processed_data, \"rawnav_summary.parquet\")\n",
    "                )\n",
    "            )\n",
    "\n",
    "            # Subset Rawnav Data to Records Desired\n",
    "            rawnav_summary_dat = rawnav_summary_dat.query('not (run_duration_from_sec < 600 | dist_odom_mi < 2)')\n",
    "            \n",
    "            rawnav_qjump_dat = rawnav_dat.merge(rawnav_summary_dat[['filename', 'index_run_start']], \n",
    "                                                on=['filename', 'index_run_start'],\n",
    "                                                how='right')\n",
    "            \n",
    "            # Address Remaining Col Format issues\n",
    "            rawnav_qjump_gdf = (\n",
    "                gpd.GeoDataFrame(\n",
    "                    rawnav_qjump_dat, \n",
    "                    geometry = gpd.points_from_xy(\n",
    "                        rawnav_qjump_dat.long,\n",
    "                        rawnav_qjump_dat.lat\n",
    "                    ),\n",
    "                    crs='EPSG:4326')\n",
    "                .to_crs(epsg=wmata_crs)\n",
    "            )\n",
    "    \n",
    "            # Iterate on over Pattern-Segments Combinations Applicable to Route\n",
    "            xwalk_seg_pattern_subset = seg_pattern[['route','pattern','seg_name_id']].copy()\n",
    "                        \n",
    "            for seg in xwalk_seg_pattern_subset.seg_name_id.unique():\n",
    "                print('Processing segment {} ...'.format(seg))\n",
    "\n",
    "                # We pass the rawnav data and summary tables, check against a segment,\n",
    "                # and use the patterns_by_seg to indicate which patterns should be examined\n",
    "                index_run_segment_start_end, summary_run_segment = (\n",
    "                    wr.merge_rawnav_segment(\n",
    "                        rawnav_gdf_=rawnav_qjump_gdf,\n",
    "                        rawnav_sum_dat_=rawnav_summary_dat,\n",
    "                        target_=segments.loc[segments.seg_name_id == seg],\n",
    "                        patterns_by_seg_=xwalk_seg_pattern_subset.loc[xwalk_seg_pattern_subset.seg_name_id == seg]\n",
    "                    )\n",
    "                )\n",
    "                # Note that because seg_pattern_first_last is defined for route and pattern,\n",
    "                # our summary will implicitly drop any runs that are on 'wrong' pattern(s) for \n",
    "                # a route. \n",
    "                \n",
    "                index_run_segment_start_end['wday'] = analysis_day\n",
    "                summary_run_segment['wday'] = analysis_day\n",
    "                \n",
    "                # The additional partitioning here is excessive, but if fits better in the \n",
    "                # iterative/chunking process above\n",
    "                pq.write_to_dataset(\n",
    "                    table = pa.Table.from_pandas(summary_run_segment),\n",
    "                    root_path = path_seg_summary,\n",
    "                    partition_cols = ['route','wday','seg_name_id']\n",
    "                )\n",
    "                \n",
    "                pq.write_to_dataset(\n",
    "                    table = pa.Table.from_pandas(index_run_segment_start_end),\n",
    "                    root_path = path_seg_index,\n",
    "                    partition_cols = ['route','wday','seg_name_id']\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (rawnav)",
   "language": "python",
   "name": "rawnav"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
